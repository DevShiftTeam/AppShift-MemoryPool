@inproceedings{GoogleResDM,
    author = {Kanev, Svilen and Darago, Juan Pablo and Hazelwood, Kim and Ranganathan, Parthasarathy and Moseley, Tipp and Wei, Gu-Yeon and Brooks, David},
    title = {Profiling a Warehouse-Scale Computer},
    year = {2015},
    isbn = {9781450334020},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2749469.2750392},
    doi = {10.1145/2749469.2750392},
    abstract = {With the increasing prevalence of warehouse-scale (WSC) and cloud computing, understanding the interactions of server applications with the underlying microarchitecture becomes ever more important in order to extract maximum performance out of server hardware. To aid such understanding, this paper presents a detailed microarchitectural analysis of live datacenter jobs, measured on more than 20,000 Google machines over a three year period, and comprising thousands of different applications.We first find that WSC workloads are extremely diverse, breeding the need for architectures that can tolerate application variability without performance loss. However, some patterns emerge, offering opportunities for co-optimization of hardware and software. For example, we identify common building blocks in the lower levels of the software stack. This "datacenter tax" can comprise nearly 30% of cycles across jobs running in the fleet, which makes its constituents prime candidates for hardware specialization in future server systems-on-chips. We also uncover opportunities for classic microarchitectural optimizations for server processors, especially in the cache hierarchy. Typical workloads place significant stress on instruction caches and prefer memory latency over bandwidth. They also stall cores often, but compute heavily in bursts. These observations motivate several interesting directions for future warehouse-scale computers.},
    booktitle = {Proceedings of the 42nd Annual International Symposium on Computer Architecture},
    pages = {158–169},
    numpages = {12},
    location = {Portland, Oregon},
    series = {ISCA '15}
}

@article{10.1145/2872887.2750392,
    author = {Kanev, Svilen and Darago, Juan Pablo and Hazelwood, Kim and Ranganathan, Parthasarathy and Moseley, Tipp and Wei, Gu-Yeon and Brooks, David},
    title = {Profiling a Warehouse-Scale Computer},
    year = {2015},
    issue_date = {June 2015},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {43},
    number = {3S},
    issn = {0163-5964},
    url = {https://doi.org/10.1145/2872887.2750392},
    doi = {10.1145/2872887.2750392},
    abstract = {With the increasing prevalence of warehouse-scale (WSC) and cloud computing, understanding the interactions of server applications with the underlying microarchitecture becomes ever more important in order to extract maximum performance out of server hardware. To aid such understanding, this paper presents a detailed microarchitectural analysis of live datacenter jobs, measured on more than 20,000 Google machines over a three year period, and comprising thousands of different applications.We first find that WSC workloads are extremely diverse, breeding the need for architectures that can tolerate application variability without performance loss. However, some patterns emerge, offering opportunities for co-optimization of hardware and software. For example, we identify common building blocks in the lower levels of the software stack. This "datacenter tax" can comprise nearly 30% of cycles across jobs running in the fleet, which makes its constituents prime candidates for hardware specialization in future server systems-on-chips. We also uncover opportunities for classic microarchitectural optimizations for server processors, especially in the cache hierarchy. Typical workloads place significant stress on instruction caches and prefer memory latency over bandwidth. They also stall cores often, but compute heavily in bursts. These observations motivate several interesting directions for future warehouse-scale computers.},
    journal = {SIGARCH Comput. Archit. News},
    month = {jun},
    pages = {158–169},
    numpages = {12}
}



@article{DynamicStorage,
    author = {Wilson, Paul and Johnstone, Mark and Neely, Michael and Boles, David},
    year = {1999},
    month = {10},
    pages = {},
    title = {Dynamic Storage Allocation: A Survey and Critical Review},
    volume = {986},
    isbn = {978-3-540-60368-9},
    journal = {In: International Workshop on Memory Management},
    doi = {10.1007/3-540-60368-9_19}
}

@article{10.1145/142181.142200,
    author = {Zorn, Benjamin and Grunwald, Dirk},
    title = {Empirical Measurements of Six Allocation-Intensive C Programs},
    year = {1992},
    issue_date = {Dec. 1992},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {27},
    number = {12},
    issn = {0362-1340},
    url = {https://doi.org/10.1145/142181.142200},
    doi = {10.1145/142181.142200},
    abstract = {Dynamic memory management is an important part of a large class of computer programs and high-performance algorithms for dynamic memory management have been, and will continue to be, of considerable interest. This paper presents empirical data from a collection of six allocation-intensive C programs. Extensive statistics about the allocation behavior of the programs measured, including the distributions of object sizes, lifetimes, and interarrival times, are presented. This data is valuable for the following reasons: first, the data from these programs can be used to design high-performance algorithms for dynamic memory management. Second, these programs can be used as a benchmark test suite for evaluating and comparing the performance of different dynamic memory management algorithms. Finally, the data presented gives readers greater insight into the storage allocation patterns of a broad range of programs. The data presented in this paper is an abbreviated version of more extensive statistics that are publically available on the internet.},
    journal = {SIGPLAN Not.},
    month = {dec},
    pages = {71–80},
    numpages = {10}
}

@article{CCPPDiff,
    author = {Calder, Brad and Grunwald, Dirk and Zorn, Benjamin},
    year = {1994},
    month = {02},
    pages = {},
    title = {Quantifying Behavioral Differences Between C and C++ Programs},
    volume = {2},
    journal = {Journal of Programming Languages}
}

@article{PageBasedDynamicMemory,
    author = {Li, Wentong and Mohanty, Saraju and Kavi, Krishna},
    year = {2006},
    month = {03},
    pages = {13 - 13},
    title = {A Page-based Hybrid (Software-Hardware) Dynamic Memory Allocator},
    volume = {5},
    journal = {Computer Architecture Letters},
    doi = {10.1109/L-CA.2006.13}
}

@inproceedings{10.1145/582419.582421,
    author = {Berger, Emery D. and Zorn, Benjamin G. and McKinley, Kathryn S.},
    title = {Reconsidering Custom Memory Allocation},
    year = {2002},
    isbn = {1581134711},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/582419.582421},
    doi = {10.1145/582419.582421},
    abstract = {Programmers hoping to achieve performance improvements often use custom memory allocators. This in-depth study examines eight applications that use custom allocators. Surprisingly, for six of these applications, a state-of-the-art general-purpose allocator (the Lea allocator) performs as well as or better than the custom allocators. The two exceptions use regions, which deliver higher performance (improvements of up to 44%). Regions also reduce programmer burden and eliminate a source of memory leaks. However, we show that the inability of programmers to free individual objects within regions can lead to a substantial increase in memory consumption. Worse, this limitation precludes the use of regions for common programming idioms, reducing their usefulness.We present a generalization of general-purpose and region-based allocators that we call reaps. Reaps are a combination of regions and heaps, providing a full range of region semantics with the addition of individual object deletion. We show that our implementation of reaps provides high performance, outperforming other allocators with region-like semantics. We then use a case study to demonstrate the space advantages and software engineering benefits of reaps in practice. Our results indicate that programmers needing fast regions should use reaps, and that most programmers considering custom allocators should instead use the Lea allocator.},
    booktitle = {Proceedings of the 17th ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
    pages = {1–12},
    numpages = {12},
    location = {Seattle, Washington, USA},
    series = {OOPSLA '02}
}

@article{ReconsideringMemory,
    author = {Berger, Emery D. and Zorn, Benjamin G. and McKinley, Kathryn S.},
    title = {Reconsidering Custom Memory Allocation},
    year = {2002},
    issue_date = {November 2002},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {37},
    number = {11},
    issn = {0362-1340},
    url = {https://doi.org/10.1145/583854.582421},
    doi = {10.1145/583854.582421},
    abstract = {Programmers hoping to achieve performance improvements often use custom memory allocators. This in-depth study examines eight applications that use custom allocators. Surprisingly, for six of these applications, a state-of-the-art general-purpose allocator (the Lea allocator) performs as well as or better than the custom allocators. The two exceptions use regions, which deliver higher performance (improvements of up to 44%). Regions also reduce programmer burden and eliminate a source of memory leaks. However, we show that the inability of programmers to free individual objects within regions can lead to a substantial increase in memory consumption. Worse, this limitation precludes the use of regions for common programming idioms, reducing their usefulness.We present a generalization of general-purpose and region-based allocators that we call reaps. Reaps are a combination of regions and heaps, providing a full range of region semantics with the addition of individual object deletion. We show that our implementation of reaps provides high performance, outperforming other allocators with region-like semantics. We then use a case study to demonstrate the space advantages and software engineering benefits of reaps in practice. Our results indicate that programmers needing fast regions should use reaps, and that most programmers considering custom allocators should instead use the Lea allocator.},
    journal = {SIGPLAN Not.},
    month = {nov},
    pages = {1–12},
    numpages = {12}
}

@article{Kenwright2012FastEF,
  title={Fast Efficient Fixed-Size Memory Pool: No Loops and No Overhead},
  publisher = {Newcastle University},
  journal = {COMPUTATION TOOLS},
  address = {Newcastle, United Kingdom},
  author = {Ben Kenwright},
  year = {2012}
}

@mastersthesis{LSU3Shell,
  author      = {Martin Kočička},
  school      = {Faculty Of Information Technology CTU In Prague},
  title       = {Performance analysis of the LSU3shell program},
  year        = {2019}
}

@article{10.1145/301589.286864,
author = {Johnstone, Mark S. and Wilson, Paul R.},
title = {The Memory Fragmentation Problem: Solved?},
year = {1998},
issue_date = {March 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/301589.286864},
doi = {10.1145/301589.286864},
abstract = {We show that for 8 real and varied C and C++ programs, several conventional dynamic storage allocators provide near-zero fragmentation, once we account for overheads due to implementation details such as headers, alignment, etc. This substantially strengthens our previous results showing that the memory fragmentation problem has generally been misunderstood, and that good allocator policies can provide good memory usage for most programs. The new results indicate that for most programs, excellent allocator policies are readily available, and efficiency of implementation is the major challenge. While we believe that our experimental results are state-of-the-art and our methodology is superior to most previous work, more work should be done to identify and study unusual problematic program behaviors not represented in our sample.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {26–36},
numpages = {11}
}

@inproceedings{10.1145/286860.286864,
author = {Johnstone, Mark S. and Wilson, Paul R.},
title = {The Memory Fragmentation Problem: Solved?},
year = {1998},
isbn = {1581131143},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/286860.286864},
doi = {10.1145/286860.286864},
abstract = {We show that for 8 real and varied C and C++ programs, several conventional dynamic storage allocators provide near-zero fragmentation, once we account for overheads due to implementation details such as headers, alignment, etc. This substantially strengthens our previous results showing that the memory fragmentation problem has generally been misunderstood, and that good allocator policies can provide good memory usage for most programs. The new results indicate that for most programs, excellent allocator policies are readily available, and efficiency of implementation is the major challenge. While we believe that our experimental results are state-of-the-art and our methodology is superior to most previous work, more work should be done to identify and study unusual problematic program behaviors not represented in our sample.},
booktitle = {Proceedings of the 1st International Symposium on Memory Management},
pages = {26–36},
numpages = {11},
location = {Vancouver, British Columbia, Canada},
series = {ISMM '98}
}

